#%
# description: Generate alleleome and corresponding PanKB files for previously generated pangenomes using BGCFlow.
# schema: schemas/config.schema.yaml
#%
report: "report/workflow.rst"


include: "rules/common.smk"

from collections import defaultdict


##### 1. Extract information from config file
(
    DF_PROJECTS,
    DF_SAMPLES,
    PROKKA_DB_TABLE,
    PROKKA_DB_MAP,
    PEP_PROJECTS,
) = extract_project_information(config)

# generate centralized sample datasets
bgcflow_util_dir = Path("data/interim/bgcflow_utils")
bgcflow_util_dir.mkdir(parents=True, exist_ok=True)
DF_SAMPLES.to_csv(bgcflow_util_dir / "samples.csv", index=False)

##### 2. Generate wildcard constants #####
PROJECT_IDS = list(DF_PROJECTS.name.unique())
STRAINS = DF_SAMPLES.genome_id.to_list()
STRAINS_FNA = DF_SAMPLES[DF_SAMPLES.input_type.eq("fna")].genome_id.to_list()
STRAINS_GENBANK = DF_SAMPLES[DF_SAMPLES.input_type.eq("gbk")].genome_id.to_list()
CUSTOM_GENBANK = DF_SAMPLES[(DF_SAMPLES.source.eq("custom")) & (DF_SAMPLES.input_type.eq("gbk"))].genome_id.to_list()
CUSTOM_FNA = DF_SAMPLES[(DF_SAMPLES.source.eq("custom")) & (DF_SAMPLES.input_type.eq("fna"))].genome_id.to_list()
NCBI = DF_SAMPLES[DF_SAMPLES.source.eq("ncbi")].genome_id.to_list()
PATRIC = DF_SAMPLES[DF_SAMPLES.source.eq("patric")].genome_id.to_list()
SAMPLE_PATHS = list(DF_PROJECTS.samples.unique())
GTDB_PATHS = [
    str(PEP_PROJECTS[k].config["gtdb-tax"])
    for k in PEP_PROJECTS.keys()
    if "gtdb-tax" in PEP_PROJECTS[k].config.keys()
]
PROKKA_GBFF = list(PROKKA_DB_TABLE.keys())
def create_defaultdict():
    return defaultdict(create_defaultdict)
RULE_FUNCTIONS = create_defaultdict()

KINGDOM = config.get("kingdom", "bacteria")

##### 3. Wildcard constraints #####
wildcard_constraints:
    strains="|".join(STRAINS),
    strains_fna="|".join(STRAINS_FNA),
    strains_genbank="|".join(STRAINS_GENBANK),
    ncbi="|".join(NCBI),
    custom_fna="|".join(CUSTOM_FNA),
    custom_genbank="|".join(CUSTOM_GENBANK),
    patric="|".join(PATRIC),
    name="|".join(PROJECT_IDS),
    prokka_db="|".join(PROKKA_GBFF),

filter_samples_qc = lambda x, y: y # No automated QC
def get_samples_for_project(wildcards):
    name = wildcards.name
    samples = DF_SAMPLES[["name"]].copy()
    samples["genome_id"] = samples.index
    samples = samples.reindex()
    samples = samples.explode("name")
    return samples.loc[samples["name"] == name, "genome_id"].to_list()
def get_samples_df_for_project(wildcards):
    name = wildcards.name
    return DF_SAMPLES.loc[get_samples_for_project(name), :]
def get_samples_df():
    return DF_SAMPLES
##### Target rules #####
# rule all:
#     input:
#         # expand("data/processed/{name}/tables/df_gtdb_meta.csv", name=PROJECT_IDS),
#         expand("data/processed/{name}/alleleome/Pan/pan_gene_syno_non_syno_df.csv", name=PROJECT_IDS),
#         #expand("data/processed/{name}/alleleome/Pan/final_core_pan_aa_thresh_vars_all_substitutions_sep_df.csv", name=PROJECT_IDS)
# 	    expand("data/processed/{name}/alleleome/Pan/dn_ds.json", name=PROJECT_IDS),
#         expand("data/processed/{name}/alleleome/Pan/step_line.json", name=PROJECT_IDS),
rule all:
    input:
        expand([
                "data/processed/{stage}/pankb/web_data/species/{name}/nova/organism.json",
                "data/processed/{stage}/pankb/web_data/species/{name}/nova/pangene.json",
                "data/processed/{stage}/pankb/web_data/species/{name}/nova/pathway.json",
                "data/processed/{stage}/pankb/web_data/species/{name}/nova/gene.jsonl.gz",
            ], stage="species", name=PROJECT_IDS)
# Create place holder for resources defined in each modules, will be added if module is included, and passed to create custom_resource_dir
resource_mapping = {}

##### 4. Generate user-defined local resources
custom_resource_dir(config["resources_path"], resource_mapping)

##### Modules #####
# include: "rules/convert_genbank.smk"
# RULE_FUNCTIONS["mash"] = {"accessions": get_samples_for_project}
# include: "rules/mash.smk"
# RULE_FUNCTIONS["automlst_wrapper"] = {"accessions": get_samples_for_project}
# include: "rules/automlst_wrapper.smk"
# include: "rules/bgc_analytics.smk"
# include: "rules/ncbi.smk"
# RULE_FUNCTIONS["prokka"] = {"samples": get_samples_df}
# include: "rules/prokka.smk"
# include: "rules/gtdb.smk"
# RULE_FUNCTIONS["roary"] = {"samples": get_samples_for_project}
# include: "rules/roary.smk"

def throw_error(wildcards):
    raise Exception()

RULE_FUNCTIONS["alleleome"]["samples"] = get_samples_for_project
RULE_FUNCTIONS["alleleome"]["pan_core"] = "Pan"
RULE_FUNCTIONS["alleleome"]["stages"] = "species"
RULE_FUNCTIONS["alleleome"]["projects"] = PROJECT_IDS
include: "rules/alleleome.smk"

RULE_FUNCTIONS["pankb_data_prep"]["projects"] = PROJECT_IDS
RULE_FUNCTIONS["pankb_data_prep"]["genomes"] = throw_error
RULE_FUNCTIONS["pankb_data_prep"]["stages"] = "species"
include: "rules/pankb_data_prep.smk"

include: "rules/pankb_nova.smk"