#%
# description: Generate pangenome, alleleome and PanKB files for a taxonomic family.
# schema: schemas/family_config.schema.yaml
#%
report: "report/workflow.rst"

include: "rules/basic.smk"
configfile: "config/config.yaml"
from snakemake.utils import validate
validate(config, schema="schemas/family_config.schema.yaml")

import pandas as pd
import numpy as np
from pathlib import Path
from collections import defaultdict
# generate centralized sample datasets
bgcflow_util_dir = Path("data/interim/bgcflow_utils")
bgcflow_util_dir.mkdir(parents=True, exist_ok=True)

def extract_custom_sample_information(custom_samples_path):
    df = pd.read_csv(custom_samples_path, index_col=0, header=0, low_memory=False)
    df.index.name = "genome_id"
    if not "path" in df.columns:
        df["path"] = np.nan
    df.loc[df["path"] == "", "path"] = np.nan
    df["source"] = "local"
    df.loc[pd.isna(df["path"]), "source"] = "ncbi"
    return df
    
def extract_project_information(config):
    # load information from config
    print(f"Step 1. Extracting project information from config...\n", file=sys.stderr)
    taxons = config["taxons"]

    taxon_records = []
    custom_samples_df = None

    for num, p in enumerate(taxons):
        print(
            f"Step 2.{num+1} Getting sample information from: {p['name']}",
            file=sys.stderr,
        )
        custom_samples_file = p.get("custom_samples", None)
        if not custom_samples_file is None:
            print(f"Step 3.{num+1} Extracting custom sample information from: {custom_samples_file}.")
            new_custom_samples = extract_custom_sample_information(custom_samples_file)
            new_custom_samples["taxon"] = p['name']
            custom_samples_df = pd.concat([custom_samples_df, new_custom_samples])
        # grab a bgcflow pep project
        record = {
            "name": p["name"].replace(" ", "_"),
            "taxon": p["name"].replace("_", " "),
            "reference_only": p.get("reference_only", True),
            "custom_samples_file": custom_samples_file,
        }
        taxon_records.append(record)
    taxons_df = pd.DataFrame.from_records(taxon_records, index="name")
    return taxons_df, custom_samples_df

##### 1. Extract information from config file
TAXONS, CUSTOM_SAMPLES = extract_project_information(config)

KINGDOM = "bacteria"

# TAXONS = extract_project_information(config)

GTDB_PATHS = []
PROKKA_DB_MAP = {}

def create_defaultdict():
    return defaultdict(create_defaultdict)
RULE_FUNCTIONS = create_defaultdict()

PANKB_ALLELEOME_ONLY = config.get("pankb_alleleome_only", False)

##### 3. Wildcard constraints #####
wildcard_constraints:
    assembly_source="all|RefSeq|GenBank",
    stage="taxon|species",
    taxon="|".join(TAXONS.index.to_list()),
    name="[a-zA-Z0-9_\-]+",

include: "rules/select_genomes/select_all_genomes.smk"

def get_taxons():
    return TAXONS.index.to_list()
def get_accessions_for_name(name):
    return get_accessions_for_taxon(name)
def get_accessions(wildcards):
    return get_accessions_for_taxon(wildcards.name)
def filter_sample_names_qc(sample_names):
    sample_names = set(sample_names)
    qc = pd.read_csv(checkpoints.qc.get().output[0], sep=",", index_col=0, header=0)
    qc_samples_names = set(qc.index[qc["passed"] == True].to_list())
    sel = list(sample_names & qc_samples_names)
    return sel
RULE_FUNCTIONS["qc"]["names"] = get_taxons()
RULE_FUNCTIONS["qc"]["stages"] = "taxon"
include: "rules/qc/qc_contigs_n50.smk"

resource_mapping = {}
if not PANKB_ALLELEOME_ONLY:
    #### Modules #####
    include: "rules/custom_genomes.smk"
    RULE_FUNCTIONS["ncbi_datasets"]["stages"] = "taxon"
    include: "rules/ncbi_datasets.smk"

    ##### 4. Generate user-defined local resources
    # custom_resource_dir(config["resources_path"], resource_mapping)

    RULE_FUNCTIONS["seqfu"]["strains"] = get_accessions
    include: "rules/seqfu.smk"
    include: "rules/checkm_for_missing.smk"
    RULE_FUNCTIONS["checkm"]["accessions"] = get_accessions
    include: "rules/checkm.smk"

    RULE_FUNCTIONS["gtdbtk_simple"]["accessions"] = lambda wildcards: get_unclassified_accessions(wildcards.stage, wildcards.name)
    include: "rules/gtdbtk_simple.smk"

    RULE_FUNCTIONS["gtdb_improved"]["taxons"] = get_taxons
    include: "rules/gtdb_improved.smk"
    include: "rules/merge_taxonomy/gtdb_and_gtdbtk.smk"
    include: "rules/eggnog.smk"


include: "rules/split_species_into_projects.smk"
if not PANKB_ALLELEOME_ONLY:
    ruleorder: extract_species_split_seqfu_stats > seqfu_combine

def filtered_accessions_for_project(name):
    return filter_sample_names_qc(get_samples_for_species_project(name))
FILTERED_ACCESSIONS = {}
def cached_filtered_accessions_for_project(wildcards):
    name = wildcards.name
    if name in FILTERED_ACCESSIONS:
        return FILTERED_ACCESSIONS[name]
    else:
        fa = filtered_accessions_for_project(name)
        FILTERED_ACCESSIONS[name] = fa
        return fa

SPECIES_PROJECTS = None
def get_projects(wildcards):
    global SPECIES_PROJECTS
    if SPECIES_PROJECTS is None:
        projects = get_species_projects()
        SPECIES_PROJECTS = projects
    return SPECIES_PROJECTS

get_samples_df = lambda wildcards: get_species_projects_samples_df()
if not PANKB_ALLELEOME_ONLY:
    include: "rules/prokka.smk"
    RULE_FUNCTIONS["roary"]["samples"] = cached_filtered_accessions_for_project
    include: "rules/roary.smk"
    RULE_FUNCTIONS["mash"]["accessions"] = cached_filtered_accessions_for_project
    include: "rules/mash.smk"
    RULE_FUNCTIONS["automlst_wrapper"]["accessions"] = cached_filtered_accessions_for_project
    include: "rules/automlst_wrapper.smk"

RULE_FUNCTIONS["ncbi_annotation_datasets"]["stages"] = "species"
RULE_FUNCTIONS["ncbi_annotation_datasets"]["accessions_for_project"] = cached_filtered_accessions_for_project
RULE_FUNCTIONS["ncbi_annotation_datasets"]["project_for_accession"] = get_species_project_for_accession
include: "rules/ncbi_annotation_datasets.smk"

RULE_FUNCTIONS["original_locus_tags"]["accession"] = cached_filtered_accessions_for_project
include: "rules/original_locus_tags.smk"

RULE_FUNCTIONS["alleleome"]["samples"] = cached_filtered_accessions_for_project
RULE_FUNCTIONS["alleleome"]["pan_core"] = "Pan"
RULE_FUNCTIONS["alleleome"]["stages"] = "species"
RULE_FUNCTIONS["alleleome"]["projects"] = get_projects
include: "rules/alleleome.smk"

include: "rules/pankb_imodulon.smk"

RULE_FUNCTIONS["pankb_data_prep"]["projects"] = get_projects
RULE_FUNCTIONS["pankb_data_prep"]["genomes"] = cached_filtered_accessions_for_project
RULE_FUNCTIONS["pankb_data_prep"]["stages"] = "species"
include: "rules/pankb_data_prep.smk"
include: "rules/pankb_nova.smk"

all_target_rules = ["classification", "pankb", "alleleome", "pankb_nova"]
def get_targets():
    defined_targets = config.get("rules", {})
    targets = [x for x in all_target_rules if defined_targets.get(x, True)]
    print(f"Active target rules: {', '.join(targets)}")
    inputs = []
    for target in targets:
        target_inputs = getattr(rules, f"{target}_all").input
        inputs.extend(target_inputs)
    print(f"Target rule inputs: {', '.join([str(s) for s in inputs])}")
    return inputs

rule all:
    input:
        get_targets()
