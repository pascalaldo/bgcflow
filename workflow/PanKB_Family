#%
# description: Generate pangenome, alleleome and PanKB files for a taxonomic family.
# schema: schemas/family_config.schema.yaml
#%
report: "report/workflow.rst"

include: "rules/basic.smk"
configfile: "config/config.yaml"
from snakemake.utils import validate
validate(config, schema="schemas/family_config.schema.yaml")

import pandas as pd
import numpy as np
from pathlib import Path
from collections import defaultdict
# generate centralized sample datasets
bgcflow_util_dir = Path("data/interim/bgcflow_utils")
bgcflow_util_dir.mkdir(parents=True, exist_ok=True)

def extract_custom_sample_information(custom_samples_path):
    df = pd.read_csv(custom_samples_path, index_col=0, header=0, low_memory=False)
    df.index.name = "genome_id"
    if not "path" in df.columns:
        df["path"] = np.nan
    df.loc[df["path"] == "", "path"] = np.nan
    df["source"] = "local"
    df.loc[pd.isna(df["path"]), "source"] = "ncbi"
    return df
    
def extract_project_information(config):
    # load information from config
    print(f"Step 1. Extracting project information from config...\n", file=sys.stderr)
    print(config)
    taxons = config["taxons"]

    taxon_records = []
    custom_samples_df = None

    for num, p in enumerate(taxons):
        print(
            f"Step 2.{num+1} Getting sample information from: {p['name']}",
            file=sys.stderr,
        )
        custom_samples_file = p.get("custom_samples", None)
        if not custom_samples_file is None:
            print(f"Step 3.{num+1} Extracting custom sample information from: {custom_samples_file}.")
            new_custom_samples = extract_custom_sample_information(custom_samples_file)
            new_custom_samples["taxon"] = p['name']
            custom_samples_df = pd.concat([custom_samples_df, new_custom_samples])
        # grab a bgcflow pep project
        record = {
            "name": p["name"].replace(" ", "_"),
            "taxon": p["name"].replace("_", " "),
            "reference_only": p.get("reference_only", True),
            "custom_samples_file": custom_samples_file,
        }
        taxon_records.append(record)
    taxons_df = pd.DataFrame.from_records(taxon_records, index="name")
    return taxons_df, custom_samples_df

##### 1. Extract information from config file
TAXONS, CUSTOM_SAMPLES = extract_project_information(config)

KINGDOM = "bacteria"

# TAXONS = extract_project_information(config)

GTDB_PATHS = []
PROKKA_DB_MAP = {}

def create_defaultdict():
    return defaultdict(create_defaultdict)
RULE_FUNCTIONS = create_defaultdict()

##### 3. Wildcard constraints #####
wildcard_constraints:
    assembly_source="all|RefSeq|GenBank",
    stage="taxon|species",
    taxon="|".join(TAXONS.index.to_list()),
    name="[a-zA-Z0-9_\-]+",

include: "rules/select_genomes/select_all_genomes.smk"

def get_taxons():
    return TAXONS.index.to_list()
def get_accessions_for_name(name):
    return get_accessions_for_taxon(name)
def filter_sample_names_qc(sample_names):
    sample_names = set(sample_names)
    qc = pd.read_csv(checkpoints.qc.get().output[0], sep=",", index_col=0, header=0)
    qc_samples_names = set(qc.index[qc["passed"] == True].to_list())
    sel = list(sample_names & qc_samples_names)
    return sel
RULE_FUNCTIONS["qc"]["names"] = get_taxons
RULE_FUNCTIONS["qc"]["stages"] = lambda: "taxon"
include: "rules/qc/qc_contigs_n50.smk"

resource_mapping = {}
#### Modules #####
include: "rules/custom_genomes.smk"
RULE_FUNCTIONS["ncbi_datasets"]["stages"] = lambda: "taxon"
include: "rules/ncbi_datasets.smk"

##### 4. Generate user-defined local resources
# custom_resource_dir(config["resources_path"], resource_mapping)

RULE_FUNCTIONS["seqfu"]["taxon"]["strains"] = get_accessions_for_taxon
include: "rules/seqfu.smk"
include: "rules/checkm_for_missing.smk"
RULE_FUNCTIONS["checkm"]["taxon"]["accessions"] = get_accessions_for_taxon
include: "rules/checkm.smk"

RULE_FUNCTIONS["gtdbtk_simple"]["taxon"]["accessions"] = lambda name: get_unclassified_accessions("taxon", name)
include: "rules/gtdbtk_simple.smk"

RULE_FUNCTIONS["gtdb_improved"]["taxon"]["taxons"] = get_taxons
include: "rules/gtdb_improved.smk"
include: "rules/merge_taxonomy/gtdb_and_gtdbtk.smk"
include: "rules/split_species_into_projects.smk"
include: "rules/eggnog.smk"

def filtered_accessions_for_project(name):
    return filter_sample_names_qc(get_samples_for_species_project(name))

RULE_FUNCTIONS["prokka"]["species"]["samples"] = get_species_projects_samples_df
include: "rules/prokka.smk"
RULE_FUNCTIONS["roary"]["species"]["samples"] = filtered_accessions_for_project
include: "rules/roary.smk"
RULE_FUNCTIONS["mash"]["species"]["accessions"] = filtered_accessions_for_project
include: "rules/mash.smk"
RULE_FUNCTIONS["automlst_wrapper"]["species"]["accessions"] = filtered_accessions_for_project
include: "rules/automlst_wrapper.smk"
RULE_FUNCTIONS["alleleome"]["species"]["samples"] = filtered_accessions_for_project
RULE_FUNCTIONS["alleleome"]["pan_core"] = lambda: "Pan"
RULE_FUNCTIONS["alleleome"]["stages"] = lambda: "species"
RULE_FUNCTIONS["alleleome"]["projects"] = get_species_projects
include: "rules/alleleome.smk"
RULE_FUNCTIONS["pankb_data_prep"]["projects"] = get_species_projects
RULE_FUNCTIONS["pankb_data_prep"]["species"]["projects"] = get_species_projects
RULE_FUNCTIONS["pankb_data_prep"]["species"]["genomes"] = filtered_accessions_for_project
RULE_FUNCTIONS["pankb_data_prep"]["stages"] = lambda: "species"
include: "rules/pankb_data_prep.smk"

all_target_rules = ["pankb", "alleleome"]
def get_targets():
    defined_targets = config.get("rules", {})
    targets = [x for x in all_target_rules if defined_targets.get(x, True)]
    print(f"Active target rules: {', '.join(targets)}")
    inputs = []
    for target in targets:
        target_inputs = getattr(rules, f"{target}_all").input
        inputs.extend(target_inputs)
    return inputs

rule all:
    input:
        get_targets()
